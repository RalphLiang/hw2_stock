{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration_梁藝鐘.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "**把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84ae491-c1db-4330-b6ca-4ac8c92e367d"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非商業用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "\n",
        "!wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 02:33:26--  http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\n",
            "Connecting to 140.115.82.54:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 818352 (799K) [text/plain]\n",
            "Saving to: ‘Eileen_Legendary.txt’\n",
            "\n",
            "Eileen_Legendary.tx 100%[===================>] 799.17K   304KB/s    in 2.6s    \n",
            "\n",
            "2021-04-12 02:33:29 (304 KB/s) - ‘Eileen_Legendary.txt’ saved [818352/818352]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "bc35f54a-7630-4b8e-9216-84d69ea0f14b"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./twodragon.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"黃易 的 大唐雙龍傳 共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "黃易 的 大唐雙龍傳 共有 930941 字詞\n",
            "包含了 3991 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一七年一月六日版》\n",
            "《好讀書櫃》典藏版\n",
            "卷四十九 第一章 矛盾之爭\n",
            "寇仲和徐子陵的震駭是有理由的，因為這是他們最害怕的事。上趟到長安尋找楊公寶庫，如被揭破，還可與高占道等人立即撤走，可是今趟卻是牽連廣泛，榮達大押的陳甫等人固是首當其衝，追查起來，平遙的歐良材等人亦難免禍。且際此李淵正深忌李世民的當兒，可能李靖也將有難，所以他們於此時分看到窗外的婠婠，立即三魂不齊，七魄不整。\n",
            "在這方面的掩飾，他們非常小心，用盡手段，想不到終被婠婠識破，最糟是直到此刻他們仍不曉得漏子出在那裏？更聯想到婠婠既可如此，暗伺在旁的石之軒自可辦到。兩人頭皮發麻，啞口無言時，婠婠從窗外飄進來，毫不客氣的坐到床端，嘴角含春的道：「兩位情郎好！你們的考慮有結果嗎？」\n",
            "寇仲正面向著她，深吸一口氣以舒緩震駭波動的情緒，沉聲道：「妳是怎樣發覺的？」徐子陵改變坐姿，雙目電射婠婠，心忖現在唯一的解決辦法，就是希望婠婠乃唯一曉得「司徒福榮計劃」的人，然後合兩人之力不擇手段拚著受傷來個殺人滅口，否則以後會被她牽著鼻子走。他肯定寇仲心中轉的是同一念頭，他不知道寇仲能否狠下此心，卻知自己肯定辦不到。\n",
            "婠婠香肩微聳，輕鬆的道：「百\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "b3195ce0-0cce-4f40-c618-a497346023c1"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "去除次數小於8的文字剩餘 : 2634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "4ede0143-d319-4bab-b375-546c057ae287"
      },
      "source": [
        "print(f\"原本 大唐雙龍傳 共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本 大唐雙龍傳 共有 930941 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘926576個字\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "36ffb85c-6959-4904-862a-267ebeab440f"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原始文字 : \n",
            "['\\n', '《', '二', '一', '七', '年', '一', '月', '六', '日', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典', '藏', '\\n', '卷', '四', '十', '九', '第', '一', '章', '矛', '盾', '之', '爭', '\\n', '寇', '仲', '和', '徐', '子', '陵', '的']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{386, 2564, 1808, 1428, 2335, 420, 2088, 2602, 2606, 2609, 1075, 2612, 2615, 2616, 2618, 957, 2622, 2624, 2246, 1863, 2632, 2122, 1867, 2007, 862, 2400, 1507, 1508, 1765, 2284, 2291, 2167, 2170}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "56a3b562-73b2-4d9f-cb07-6f109c2f3302"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[2622 1507 2284 2624 1428 2167 2624 2170 1808 2246 1508 2622 1507 2564\n",
            "  386 1863  420 1508  862 2007 2622], shape=(21,), dtype=int32)\n",
            "['\\n', '《', '二', '一', '七', '年', '一', '月', '六', '日', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典', '藏', '\\n']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[1075 2335 2400 2122 2088 2624  957 1867 1765 2606 2291 2622 2616 2615\n",
            " 2602 2609 2618 2612 2632 2216 1497], shape=(21,), dtype=int32)\n",
            "['卷', '四', '十', '九', '第', '一', '章', '矛', '盾', '之', '爭', '\\n', '寇', '仲', '和', '徐', '子', '陵', '的', '震', '駭']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "d8ef69a6-37fa-4fc8-d133-f0853c7b10ee"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "299f1093-3688-4e37-c9ad-f37372f3ab58"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : ['\\n', '《', '二', '一', '七', '年', '一', '月', '六', '日', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典', '藏']\n",
            "Target: ['《', '二', '一', '七', '年', '一', '月', '六', '日', '》', '\\n', '《', '好', '讀', '書', '櫃', '》', '典', '藏', '\\n']\n",
            "--------------------------------------------------\n",
            "Input : [2622 1507 2284 2624 1428 2167 2624 2170 1808 2246 1508 2622 1507 2564\n",
            "  386 1863  420 1508  862 2007]\n",
            "Target: [1507 2284 2624 1428 2167 2624 2170 1808 2246 1508 2622 1507 2564  386\n",
            " 1863  420 1508  862 2007 2622]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "a421ffd3-133c-46d1-c161-038e2811b0af"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 20), (64, 20)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "5cd13b35-2194-4b1b-8901-bc8a3c683f5b"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 512)         1348608   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 4096)        75513856  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, None, 2048)        50339840  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 2634)        5397066   \n",
            "=================================================================\n",
            "Total params: 132,599,370\n",
            "Trainable params: 132,599,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "483de790-7e68-49dd-b094-188ddca38d5b"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 2634)\n",
            "Model target shape : (64, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "53a48d3f-ef81-4fe4-ff2c-38c95a7c64d3"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "次馳想幽林小谷是怎樣一處人間勝地，直至此\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "德童童童童癸癸癸癸癸愁愁袍袍遞流虛秀秀秀\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "594b9aeb-9e63-4a4e-86d6-f6debb0af180"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "689/689 [==============================] - 249s 358ms/step - loss: 6.0378\n",
            "Epoch 2/20\n",
            "689/689 [==============================] - 247s 358ms/step - loss: 4.7095\n",
            "Epoch 3/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 4.2271\n",
            "Epoch 4/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 3.8979\n",
            "Epoch 5/20\n",
            "689/689 [==============================] - 247s 358ms/step - loss: 3.6023\n",
            "Epoch 6/20\n",
            "689/689 [==============================] - 247s 358ms/step - loss: 3.3088\n",
            "Epoch 7/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 2.9840\n",
            "Epoch 8/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 2.6185\n",
            "Epoch 9/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 2.2152\n",
            "Epoch 10/20\n",
            "689/689 [==============================] - 247s 358ms/step - loss: 1.7870\n",
            "Epoch 11/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 1.3720\n",
            "Epoch 12/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 1.0066\n",
            "Epoch 13/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.7343\n",
            "Epoch 14/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.5606\n",
            "Epoch 15/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.4684\n",
            "Epoch 16/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.4228\n",
            "Epoch 17/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.4027\n",
            "Epoch 18/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.3920\n",
            "Epoch 19/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.3877\n",
            "Epoch 20/20\n",
            "689/689 [==============================] - 247s 359ms/step - loss: 0.3823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "790c3849-2ef3-4ec4-fd43-29646fc76c3a"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "8e3c15c2-7886-48ac-f915-52c3877b085e"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "次馳想幽林小谷是怎樣一處人間勝地，直至此\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "見想幽林小谷是怎樣一處人間勝地，直至此刻\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151400cb-376c-41bc-a477-f5e9ab2b951a"
      },
      "source": [
        "init_seq = \"石青璇苦笑\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "石青璇苦笑道：「我不是不想當皇帝。」\n",
            "徐子陵一呆道：「竟有此事？」\n",
            "雲玉真點頭道：「我今天雖是一針見血的見老哥，不過這可怕現在既然對方絕無的事。」\n",
            "寇仲道：「我們亦有一件事請你幫忙。」\n",
            "沈落雁撫著胸口，一手一字道：「他怎能不付楊虛彥？」\n",
            "侯希白笑道：「我和子陵因何欲意見雷大哥，老天爺仍一命去見她。」徐子陵欣然道：「難怪子陵會告訴我她，卻是你的情況。」寇仲欣然道：「難怪子陵剛才大叫不好。」\n",
            "寇仲信心十足的道：「我們是否真的對這裏來？」\n",
            "徐子陵道：「我們可經由水路往一塊兒送送你們，到那裏去？」\n",
            "跋鋒寒失聲道：「我今晚來，是要代李世民說服他？」跋鋒寒頹然道：「這叫愛夫情切嘛！」\n",
            "徐子陵立即精神大振，道：「這方面朕交由少帥全權負責，應是塞外聯軍南下的非常時期，從軍事角度考慮，李世民閉上帝位。」\n",
            "寇仲向韋公公道：「有甚麼好打算？」\n",
            "劉黑闥沉聲道：「我要去見李世民。」\n",
            "寇仲大吃一驚道：「喜兒妳尚未有意中人嗎？」陰顯鶴老臉通紅的道：「她不是說過的嗎？」\n",
            "傅君瑜淡淡道：「若我沒有猜錯，傅采林是否要到長安來？」徐子陵笑道：「你有把握穿透對方的人，我會盡力而為，好卻好！我們今趟來是要全力運作出來的軍事行動，你們怎可如此魯莽，難道不曉得大唐宮中人殺人，且是默許建成、元吉的人，所以能對任何人更清楚答案。\n",
            "沈落雁細審他神色，黛眉輕蹙道：「大帥曉得此人叫要看醒，若是福榮爺的人。」\n",
            "頓頓續道：「我曾為劉弘基方面都沒有問題"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    }
  ]
}