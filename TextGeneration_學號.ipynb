{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-學號.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "**把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84ae491-c1db-4330-b6ca-4ac8c92e367d"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非商業用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "\n",
        "!wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 02:33:26--  http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\n",
            "Connecting to 140.115.82.54:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 818352 (799K) [text/plain]\n",
            "Saving to: ‘Eileen_Legendary.txt’\n",
            "\n",
            "Eileen_Legendary.tx 100%[===================>] 799.17K   304KB/s    in 2.6s    \n",
            "\n",
            "2021-04-12 02:33:29 (304 KB/s) - ‘Eileen_Legendary.txt’ saved [818352/818352]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "e08b9ebf-9aab-465b-8b6a-f962883b8dd4"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./Eileen_Legendary.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"張愛玲散文集共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "張愛玲散文集共有 274000 字詞\n",
            "包含了 3665 個獨一無二的字 (含標點符號)\n",
            "\n",
            "我自己從來沒想到需要辯白，但最近一年來常常被人議論到，似乎被列為文化漢奸之一，自己也弄得莫名其妙。我所寫的文章從來沒有涉及政治，也沒有拿過任何津貼。想想看我唯一的嫌疑要末就是所謂「大東亞文學者大會」第三屆曾經叫我參加，報上登出的名單內有我；雖然我寫了辭函去，（那封信我還記得，因為很短，僅只是：「承聘為第三屆大東亞文學者大會代表，謹辭。張愛玲謹上。」）報上仍舊沒有把名字去掉。\n",
            "至於還有許多無稽的謾罵，甚而涉及我的私生活，可以辯駁之點本來非常多。而且即使有這種事實，也還牽涉不到我是否有漢奸嫌疑的問題；何況私人的事本來用不著向大眾剖白，除了對自己家的家長之外彷彿我沒有解釋的義務。所以一直緘默著。同時我也實在不願意耗費時間與精神去打筆墨官司，徒然攪亂心思，耽誤了正當的工作。但一直這樣沉默著，始終沒有闡明我的地位，給社會上一個錯誤的印象，我也覺得是對不起關心我的前途的人。所以在小說集重印的時候寫了這樣一段作為序。反正只要讀者知道了就是了。\n",
            "※※※\n",
            "《傳奇》裏面新收進的五篇，「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」，初發表的時候有許多草率的地方，實在對讀者感到抱歉，這次\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "bb4c36ec-ba5c-4dbf-c2dd-32a1190c23e0"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "去除次數小於8的文字剩餘 : 1973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "c6652877-c1c6-4249-dd72-bbcc10348040"
      },
      "source": [
        "print(f\"原本張愛玲散文集共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本張愛玲散文集共有 274000 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘268660個字\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "ee6961cc-6ba1-45f4-852f-53232087fb47"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原始文字 : \n",
            "['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常', '被', '人', '議', '論', '到', '，', '似', '乎', '被', '列', '為', '文', '化', '漢', '之', '一', '，', '自', '己']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{1921, 1540, 1799, 1929, 1937, 659, 1428, 1558, 1053, 1954, 1955, 1188, 1958, 1968, 178, 1972, 1854, 1730, 1731, 1618, 1876, 1885, 1890, 1891, 1636, 99, 614, 1646, 1905, 1907, 1781}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "df09ddc1-4981-4f96-8ed5-b0f0a7f51ef5"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[1954 1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730\n",
            " 1636 1558 1968 1885 1958 1731 1731], shape=(21,), dtype=int32)\n",
            "['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[1646 1955 1053 1428 1937 1972 1799 1540 1646   99 1905 1618 1188  178\n",
            " 1781 1968 1972 1907 1876 1942 1470], shape=(21,), dtype=int32)\n",
            "['被', '人', '議', '論', '到', '，', '似', '乎', '被', '列', '為', '文', '化', '漢', '之', '一', '，', '自', '己', '也', '弄']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "96fef27d-927f-4ce9-dd28-cc00f39abcff"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "29bfe6e8-8fff-44ce-e39d-468dffc7c75e"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : ['我', '自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常']\n",
            "Target: ['自', '己', '從', '來', '沒', '想', '到', '需', '要', '辯', '白', '，', '但', '最', '近', '一', '年', '來', '常', '常']\n",
            "--------------------------------------------------\n",
            "Input : [1954 1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730\n",
            " 1636 1558 1968 1885 1958 1731]\n",
            "Target: [1907 1876 1854 1958 1929 1890 1937  659 1921  614 1891 1972 1730 1636\n",
            " 1558 1968 1885 1958 1731 1731]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "0ff52933-08a1-4ae4-eecd-9a23c12849a1"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 20), (64, 20)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "fea246b0-bf03-4dae-8cce-6764dc62fa0d"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 512)         1010176   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 4096)        75513856  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 2048)        50339840  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 1973)        4042677   \n",
            "=================================================================\n",
            "Total params: 130,906,549\n",
            "Trainable params: 130,906,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "6b770b09-58b7-48d2-e00d-936641c65b47"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 1973)\n",
            "Model target shape : (64, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "573c5da5-c783-400f-fbf8-54dcf435345d"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "太微笑著，並不和他辯，自顧自喚阿媽取過碗\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "哄珠星捨捨帳帳吊吊吊吊吊吊吊吊吊香香撲羊\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "f6c26072-258a-4be9-84d4-b1221daa4842"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "199/199 [==============================] - 77s 377ms/step - loss: 6.3566\n",
            "Epoch 2/20\n",
            "199/199 [==============================] - 75s 376ms/step - loss: 5.4032\n",
            "Epoch 3/20\n",
            "199/199 [==============================] - 75s 375ms/step - loss: 4.8969\n",
            "Epoch 4/20\n",
            "199/199 [==============================] - 75s 377ms/step - loss: 4.5331\n",
            "Epoch 5/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 4.2807\n",
            "Epoch 6/20\n",
            "199/199 [==============================] - 76s 378ms/step - loss: 4.0603\n",
            "Epoch 7/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 3.8509\n",
            "Epoch 8/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 3.6136\n",
            "Epoch 9/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 3.3549\n",
            "Epoch 10/20\n",
            "199/199 [==============================] - 76s 379ms/step - loss: 3.0634\n",
            "Epoch 11/20\n",
            "199/199 [==============================] - 76s 378ms/step - loss: 2.7200\n",
            "Epoch 12/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 2.3304\n",
            "Epoch 13/20\n",
            "199/199 [==============================] - 76s 378ms/step - loss: 1.8835\n",
            "Epoch 14/20\n",
            "199/199 [==============================] - 76s 378ms/step - loss: 1.4246\n",
            "Epoch 15/20\n",
            "199/199 [==============================] - 75s 377ms/step - loss: 0.9859\n",
            "Epoch 16/20\n",
            "199/199 [==============================] - 75s 377ms/step - loss: 0.6511\n",
            "Epoch 17/20\n",
            "199/199 [==============================] - 75s 377ms/step - loss: 0.4386\n",
            "Epoch 18/20\n",
            "199/199 [==============================] - 75s 377ms/step - loss: 0.3366\n",
            "Epoch 19/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 0.2957\n",
            "Epoch 20/20\n",
            "199/199 [==============================] - 75s 378ms/step - loss: 0.2739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a07e4971-c1ea-4316-d8e1-bdc8e20ddfd1"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "9ac92c16-7ba8-46c1-ce61-1979e22a8414"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "原本的中文字序列：\n",
            "太微笑著，並不和他辯，自顧自喚阿媽取過碗\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "太笑著，並不和他辯，自顧自喚阿媽取過碗櫥\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da87ab9-3efb-4f4c-9a08-f59b2a43a88d"
      },
      "source": [
        "init_seq = \"紅玫瑰\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "他心裏的一跳，彷彿十年前的事又多死了，然而三十年前……那是最可以的事。」流蘇道：「那怕不行。我不能夠離婚。我們那邊的愛，是不完全的。你母親……」世舫站定了腳。\n",
            "隔了一會，問道：「你這樣的就吃了，玩也玩不成？」\n",
            "話心說：「唔，唔，」地叫：「哥兒達先生，你很少說話。」雲藩笑道：「你這不是鬧著的時候，你再要把它跟了出來，讓她們見過了，是不成的親戚，她一定會答應他。的確，他從來沒有這麼的清醒過來，他們的同學們也沒有，惟有一個不在上面，只是一點空白，一點一點，到了夏天，只怕被他們的舍監的一個安靜的口氣。他們也許並不是悠久的無的快樂。她說：「不過他們一點兒了，」他們說：「不，讓我出去罷！」\n",
            "宗楨道：「我不能夠離婚。我們那時候，如果沒讓她，他一定能夠利用這一切。\n",
            "她的眼睛被他的手臂為了她的腳，直射到她的臉上。\n",
            "樓上的一隻腳，劈手搭在要走了。他沒有想到沒有，只有她一個人在這兒。\n",
            "他的臥室的角落裏堆�\n",
            "�一隻大籐箱，裏面高高地，慌音裏彷彿一陣陰風吹過，蜜秋兒太太半晌沒有坐，在簫黑的沙發上，一陣風把所有的插戴全剝了下來，還了老太太，振保把門關在玻璃上，被紙上的簾子向後斜著一張，查不及地一下"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}